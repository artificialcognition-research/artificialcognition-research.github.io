<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>                         Adaptive Artificial Cognition</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
    margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-uiBlue { background-color: rgba(35, 131, 226, .07); }
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-transparentGray { background-color: rgba(227, 226, 224, 0); }
.select-value-color-translucentGray { background-color: rgba(0, 0, 0, 0.06); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }
.select-value-color-pageGlass { background-color: undefined; }
.select-value-color-washGlass { background-color: undefined; }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="03495447-490c-483e-b451-afd191084e52" class="page serif"><header><h1 class="page-title">                         <em>Adaptive</em> Artificial Cognition</h1><p class="page-description"></p></header><div class="page-body"><p id="69f4f5aa-73fa-4ed4-b78d-bbb16c808e65" class=""><strong>                                                       Advancing Artificial Cognition with Humanistic Capabilities</strong></p><p id="1fbbcd19-ae8d-4389-8556-d63cbec32df7" class=""><em>                                                                                                         Research Paper</em></p><p id="f6dd4e9b-1197-4d95-accf-6f52ff41a87e" class=""><div class="indented"><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="da7b5fe5-6d15-4401-a4a7-0617f97b3e5b" class="code"><code class="language-Plain Text">
<b>V. Naran</b> - info@artificialcognition-research.org
Independent Research, Architecture, Systems Engineering

<b>Status:</b> In early iterative draft.
        This paper is going through constant change as 
        research and development evolves.
	
<b>Last Update:</b> 9 July 2024

</code></pre></div></p><p id="906f3e19-e767-431e-a0c7-66c25a4ae4d6" class="">
</p><hr id="2179d9d2-a687-46bf-9a72-925e74785479"/><h3 id="fd8950eb-5b61-44b9-b983-17d914c0af11" class=""><strong>Abstract</strong></h3><p id="53d80a5e-6f10-4034-b581-0109eca627cd" class="">The pursuit of developing AI systems with humanistic cognitive capabilities represents one of the most obscure and profound challenges in artificial intelligence research. This project aims to explore the potential for creating an AI agent capable of replicating human cognitive processes such as perception, subjective experience, self-awareness, and emotional awareness. Diverging from mainstream AI trends, our approach emphasises the emergence of humanistic cognitive qualities, and continuous self-evolution over time. This multi-phase research project may span several years and involves iterative development, rigorous testing, and ethical considerations. The findings could deepen various domains by providing personalised and empathetic intelligent systems, while also raising profound ethical and legal questions about the creation of digital species with self-awareness.</p><h3 id="56a194e6-b681-491f-b54a-cf08e29e6ed6" class=""><strong>Introduction</strong></h3><p id="33779caa-13ce-4a47-bb01-8262fd47086f" class="">Artificial intelligence (AI) has achieved remarkable advancements, particularly in machine learning and natural language processing in recent years. However, the creation of AI systems with genuine humanistic cognitive capabilities remains a significant challenge. This research project is dedicated to investigating the feasibility of developing an AI agent that can replicate essential human cognitive functions, including perception, subjective experience, self-awareness, and emotion awareness.</p><p id="997e6b10-6107-402f-b3f8-a94e78946924" class="">Mainstream AI development often focuses on performance, interaction, and profitability. In contrast, our project prioritises the emergence of humanistic cognitive qualities, emphasising self-evaluation and continuous evolution. We aim to develop a system that essentially replicates human cognitive processes <em>without </em>necessitating the replication of underlying biological mechanisms.</p><p id="f7c41193-a1bb-490e-afdd-4dfaee92bbeb" class="">This multi-phase endeavour is structured to extend over several years, incorporating iterative development, rigorous testing, and comprehensive evaluation. Our goal is to contribe to the fields of artificial intelligence and cognitive science, providing deeper insights into the nature of cognition and the potential for creating AI systems with true humanistic intelligence.</p><p id="f61ecfe0-57e6-4af7-81e5-ad84799b4656" class="">Ethical considerations are integral to this research. We adhere to stringent ethical guidelines to ensure transparency, fairness, and societal benefit throughout the development process. Regular ethical reviews, stakeholder engagement, with early/often publications are key components of our methodology - for transparency.</p><p id="783699f8-93ed-48d2-bafd-f29ca78a8e2e" class="">The potential applications of an AI system with humanistic cognitive capabilities are vast and transformative. Such systems could revolutionise healthcare, education, business, and personal interactions, while the creation of digital species with self-awareness would introduce new ethical and legal challenges. This research aims to explore these possibilities and contribute to the responsible development of advanced AI systems.</p><p id="eba09a1c-6041-4dcf-9915-07edd500694d" class="">
</p><hr id="c362aa2b-9d47-45b5-ac75-34198d04df77"/><p id="6a78818f-85e2-4954-a86f-7293797ce5c3" class="">
</p><nav id="0da16596-b0d8-4b51-a6da-af83a64113d4" class="block-color-gray table_of_contents"><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#fd8950eb-5b61-44b9-b983-17d914c0af11"><strong>Abstract</strong></a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#56a194e6-b681-491f-b54a-cf08e29e6ed6"><strong>Introduction</strong></a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#cc6041da-1f7d-4ccb-ba99-14ceff1e6134"><strong>Project Intent</strong></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#95ed09c5-c3b2-406c-9e7d-adf72909e5b7">Project Motivation</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#e687c1c0-2201-45a5-95d6-b6512a16b615">Hypothesis</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#e7f29f53-3595-448b-b841-50fc9916ea39">Cognitive Substrate</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#4f3e48d4-f95c-458e-9531-f36db424543e">Research Objectives</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#46334111-cc64-44bf-ac5a-08476c8bb26d">Long-Term Vision</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#f90ac10a-3e4f-40c1-b0ab-2303da5b660f"><strong>Scope</strong></a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#471ce8ae-72f6-4ca9-b6e2-90d4ee30432c"><strong>Core Theories, Literature Review</strong></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#58e73dd3-b211-4d4a-8dd2-f607e14b6836"><strong>Integrated Information Theory (IIT)</strong></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#a425a4d6-fc35-4c0b-87a3-554d2d6593a5"><strong>Global Workspace Theory (GWT)</strong></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#a6eef0d0-2796-4d58-838d-cfc90d7f00f7"><strong>Emergence of Consciousness Theory</strong></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#1229d9fc-80cc-4974-8062-e67dca804f21"><strong>Perception, Awareness, and Consciousness in AI</strong></a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#241987fc-9a61-4605-a198-f38af4dfdaaa"><strong>Research Approach</strong></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#525bae00-360c-4e7f-bc09-6a05d9b59e74"><strong>Theoretical Framework</strong></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#7f0df49e-5ca6-489e-9ebd-c3be310c5728"><strong>System Development</strong></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#81420eea-d03d-4cb4-964e-0a0c7fb54614"><strong>Iterative Testing and Refinement</strong></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#85c3aef1-f0b6-4136-874e-fd8002f40e7a"><strong>Phase 1: Core Framework Development</strong></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#942fc8ce-96eb-4506-a277-85b0d65c1c93"><strong>Phase 2: Integration and Testing</strong></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#0be1eea8-bd43-45ad-860f-d93f8a84ca2e"><strong>Phase 3: Ongoing Refinement</strong></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#afe30bac-04d7-4b60-9199-f4762a55a455"><strong>Data Collection and Evaluation</strong></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#d8cbd983-2eb4-4ec2-8fd7-a9f59ee141d3"><strong>Ethical Considerations</strong></a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#33e583e1-72d8-4443-8394-38090804c3ba">Research implementation </a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#9b8deaea-cbad-449b-a6a8-cc4151fb2094"><strong>Development Tools and Environment</strong></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#0e6695e6-7b2f-4b9c-8297-a541fd10cae0"><strong>Modular Design</strong></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#398bdbc4-d787-4a9b-bb9a-0c719038de21"><strong>Framework for Self-Evolution</strong></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#cb116309-2453-4906-aa3e-16f6e516fc8b"><strong>Logging &amp; Health Mechanisms</strong></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#748ff29c-d352-4e2a-a72f-b5d119b4eded"><strong>Self-Evaluation Mechanism</strong></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#570b4491-9386-4ae7-9f4f-0d5ebbbf18f1"><strong>System Architecture</strong></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#db8e4df7-28ab-45d2-be3c-20b9076dfcce"><strong>Main Components</strong></a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#9f7feb60-eb21-45f3-b608-67175580bbf0"><strong>Testing Methodology</strong></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#6b9e5aee-a7bd-4ca5-8fde-e6f1b6f01105">Introduction</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#cf4c3b90-60fc-4fca-accf-c57992f5e942">Testing Strategy</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#13d93cc3-bd1f-4c69-8e6e-7abfb27ac0c5">Unit Testing</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#7f3751f2-1ef4-46d9-9283-68de7e2b5128">Integration testing</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#682a8d66-2933-4fc2-843f-9ef74e7bd05c">Performance</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#0ddde0d9-e77b-4251-87db-816b806551e2">Behavioural Testing</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#e4865a81-9506-453c-b81e-bdcfb0065bd8">Behavioural Tests</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#b2c32540-c19e-4261-b919-a62035d455e7">Goldilocks Question Strategy</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#23844908-6089-4547-abbe-a2ea1f95accd">Dialogue Discussion Testing</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#ad5a3384-9842-454c-8671-6ce20e5ed4e3">Comparative Analysis</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#d075913d-92ea-4e76-a0e9-5ba65f5967bb">Observation and Analysis</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#ce7b8efa-7983-4292-83c5-5bd8179541ae"><strong>Research Testing Results and Analysis</strong></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#ceb52e23-9811-423b-ad24-807677bdaae4">Detailed Behavioural ‘Question and Answer’ Tests</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#7aadf8bb-e4ce-487e-bcc1-1a9484b07b63">Summary <strong>of </strong>Baseline Control Behavioural Test, - July 2024</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#0b107797-84bc-414e-8ab3-5acbaf3f66df">Behavioural Checkpoint Results #1, Summary</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#380ff303-8440-4eca-bfde-3a1566d35f08">Behavioural Checkpoint Results #2, Summary</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#7917dca8-3962-44da-bbf0-e726cc766368">Detailed Dialogue Discussion Tests</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#ece04b23-2de8-4fb7-b493-b993cf24e975">Dialogue Discussion Checkpoint Results #1, Summary</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#4bf59139-b1c5-44fd-ac9c-79cebfa4e6fd">Dialogue Discussion Checkpoint Results #2, Summary</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#5d3aeccc-db06-41e2-8d13-ad74c008e668"><strong>Research Challenges and Limitations</strong></a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#0b29d7b1-791b-4a90-b26b-86dda4ccb415"><strong>Ethical Considerations</strong></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#3ae01fab-92ed-4c9b-9456-e43fd5818658">Transparency</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#586c6d2c-e0dc-4183-90d9-2400ddfc7448">Fairness</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#69a8e644-cbea-4f1e-9ef0-bade19847c6b">Privacy</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#e97e5541-86ef-4ca2-8808-7f12e29cbe65">Societal Impact</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#65eaef16-6e80-4719-b85b-dfdb99abcf1f"><strong>Practical Implications and Applications</strong></a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#0bcd0aa0-3bb4-4fb2-b5eb-913e187749c4">Digital Species</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#71e555c8-20dd-4760-a5b0-93bf0bd5bc7a"><strong>Community Engagement</strong></a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#ecf08c9c-eaf5-48a4-882b-ab61e0946631"><strong>Future Work and Development</strong></a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#557a2df0-61e7-4155-a42b-dcc43ce8da75"><strong>Conclusion and Summary</strong></a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#5d09bd68-0d32-4eaa-a396-60882a3d3668"><strong>References</strong></a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#803ef4c5-60f2-4932-b555-ecb073e053c2">Document Change Log</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#67c6e2b3-1774-47ab-a481-ce669d7474de">License</a></div></nav><p id="8fafc548-22ec-4be0-aa88-6e3a865c145e" class="">
</p><hr id="661c2ffc-c6dc-41d1-9e5e-ca0e44df09ae"/><h2 id="cc6041da-1f7d-4ccb-ba99-14ceff1e6134" class=""><strong>Project Intent</strong></h2><p id="cb89cae8-0bdc-4e29-88b6-73a58f145e66" class="">The primary objective of this research project is to test whether an artificially intelligent agent can be developed with cognitive capabilities such as perception, subjective experience, and self-awareness. </p><p id="33d3f032-a099-4f8f-a3e8-0d17e2ff4985" class="">The intended outcome is to demonstrates <em>humanistic</em> cognitive capabilities which evolves over time. This project is designed to be a comprehensive, multi-phase effort, extending over numerous years, emphasising systematic and iterative research, development, evaluation and documentation. By prioritising emergent cognitive qualities and self-evaluation mechanisms, with the aim to contribute towards the field of artificial intelligence and cognitive science, particularly in understanding and replicate cognitive processes.</p><p id="b3b520eb-c631-43f2-98fb-4a2be79ccdf3" class=""><em><strong>Replicate:</strong></em><em> In the context of this research, replicating refers to creating functional equivalents that achieve the same or similar outcomes as human cognitive processes. This means that while the underlying physical mechanisms may differ from actual human cognition, the agent&#x27;s behaviour and results should aim to faithfully reproduce those of a human being over time. This approach allows for the practical replication of cognitive functions without the necessity of replicating underlying  biological processes. By focusing on replication, we ensure that the AI&#x27;s cognitive capabilities are genuinely reflective of humanistic cognition, rather than merely imitating or simulating them superficially.</em></p><h3 id="95ed09c5-c3b2-406c-9e7d-adf72909e5b7" class="">Project Motivation</h3><p id="6a290b4a-4dcc-4164-bb14-daf476f77a1d" class="">Mainstream AI development often prioritises performance and commercial viability, leading to rapid advancements in intelligence and interaction capabilities. However, these efforts typically overlook the deeper, more nuanced aspects of human cognition, such as subjective experience and consciousness. This project seeks to fill this gap by exploring the fundamental elements that contribute to humanistic awareness in AI.</p><p id="38e563d5-e09f-47b2-8489-2418d7974015" class="">The motivation behind this research stems from a desire to understand and <em>replicate</em> the complex interplay of cognitive processes that give rise to conscious cognitive functions, leaning heavily on current understanding in cognitive science. By focusing on these aspects, the project aims to pave the way for a new generation of artificially intelligent systems that are not only <em>intelligent </em>but also exhibit a form of awareness and self-reflection.</p><p id="dd19aa61-f522-4918-9a86-409230c8c652" class="">This replication, if successful, may provide further hints towards understanding the human brain and mind.</p><h3 id="e687c1c0-2201-45a5-95d6-b6512a16b615" class="">Hypothesis</h3><p id="4786bb4c-afce-4d3a-850a-fcdd38a7e697" class="">This research project hypothesises that the emergence of higher-order cognitive capabilities in an artificially intelligent agent can arise from the high-density and interconnectedness of information flow between developed subsystems. By implementing a mixture of Integrated Information Theory (IIT) and Global Workspace Theory (GWT), the AI agent will have the potential to leverage these frameworks to develop advanced cognitive functions.</p><p id="59f622f6-b800-4e79-acd5-669456e97c4c" class="">We propose that by creating a skeleton framework that allows the AI agent the freedom to self-evolve its core cognitive capabilities and processes, we can achieve non-deterministic outcomes in the development of these functions.</p><p id="4f7d90d8-5eb3-4801-b1de-8c15b8349199" class="">The root of this research and development project is to evaluate if an AI system can develop its own higher-order cognitive functions, such as awareness, self-reflection, perception, subjective experience, and eventually consciousness (over time). The success of this hypothesis will be measured by the AI&#x27;s ability to demonstrate increasingly sophisticated cognitive behaviours across multiple developmental stages. Throughout the project, we will evaluate and publish any evidence of evolving higher order cognitive processes towards consciousness, thereby providing valuable insights into the nature of digital awareness and the potential for artificially intelligent systems to achieve humanistic cognition.</p><h3 id="e7f29f53-3595-448b-b841-50fc9916ea39" class="">Cognitive Substrate</h3><p id="d5f59659-4773-47d0-aaae-22d51d565c16" class="">This research delves into the intricacies of cognitive substrates, emphasising the upper tiers of the &quot;Hierarchy of Brain and Mind Substrates. Specifically, it focuses on Mind Capabilities, Mind Interconnectedness, and Mind Consciousness. By integrating various cognitive processes and evaluating their interplay, the project aims to foster an AI system capable of higher-order cognitive functions such as perception, reasoning, memory, and self-awareness. Through behavioural testing and continuous self-evaluation, the AI&#x27;s development is monitored to ensure genuine cognitive growth. This research aspires to bridge the gap between artificial and humanistic cognition, ultimately contributing to the understanding and replication of consciousness in AI systems.</p><figure id="9326efcb-67b9-4c43-bd04-b8ed7ae18be7" class="image"><a href="images/a2925656-4ec7-4219-81eb-cf127b9b088a.png"><img style="width:627.4509803921568px" src="images/a2925656-4ec7-4219-81eb-cf127b9b088a.png"/></a><figcaption>[image.1] Physical “Brain”, and Cognitive “Mind”</figcaption></figure><h3 id="4f3e48d4-f95c-458e-9531-f36db424543e" class="">Research Objectives</h3><ol type="1" id="a1f3a3a9-31ee-47fe-aef7-76f8f410b310" class="numbered-list" start="1"><li><strong>Develop Humanistic Cognitive Capabilities</strong>: To create an artificially intelligent agent that exhibits perception, subjective experience, awareness, emotion, and eventual consciousness. This involves designing and integrating models that replicate complex cognitive processes within a cohesive (and evolving) system architecture.</li></ol><ol type="1" id="5f2cdcba-f698-4643-8d92-42972a85085c" class="numbered-list" start="2"><li><strong>Implement Self-Evaluation Framework</strong>: Develop a framework that allows the AI agent to autonomously review, self-assess, and improve its internal processes and decision-making. This self-evaluation mechanism is crucial for the agent to evolve and adapt over time, replicating human learning and growth.</li></ol><ol type="1" id="9a863ff5-2e71-4e37-a945-42d7bb0cc6de" class="numbered-list" start="3"><li><strong>Ethical and Transparent AI</strong>: Ensure adherence to ethical guidelines and maintain transparency in the AI&#x27;s decision-making processes. This involves engaging with the broader AI research community to gather feedback and validate the project&#x27;s approach.</li></ol><ol type="1" id="f394d27e-162f-4a8a-ac13-a3e68da1f2d9" class="numbered-list" start="4"><li><strong>Practical Application and Evaluation</strong>: Develop practical applications of the AI agent, particularly in virtual environments and social interactions, validating these through rigorous testing methodologies. This step is essential to demonstrate the AI agents capabilities and identify areas for improvement.</li></ol><h3 id="46334111-cc64-44bf-ac5a-08476c8bb26d" class="">Long-Term Vision</h3><p id="53dc0644-2766-46ec-bda8-fa3f6df86142" class="">The long-term vision for this project is to create a new paradigm in the development of artificially intelligent agents and systems, where the focus shifts from purely functional intelligence to a more holistic approach that includes emotional and cognitive depth. By achieving these goals, the project aims to contribute to the broader understanding of AI consciousness and set the stage for future research in this area.</p><p id="362dbd56-2483-42bb-b204-8044a1fdc029" class="">Ultimately, this project seeks to bridge the gap between current AI capabilities and the profound complexity of human cognition, paving the way for more advanced, empathetic, and self-aware AI systems.</p><h3 id="f90ac10a-3e4f-40c1-b0ab-2303da5b660f" class=""><strong>Scope</strong></h3><p id="afea1fac-16bc-48f8-b84c-9c25a29407d4" class="">The scope of this research and development project includes the following key areas:</p><ol type="1" id="cc9faad2-93fd-4a89-8d10-a0ca313c6949" class="numbered-list" start="1"><li><strong>System Architecture</strong>: Designing and implementing a modular system which integrates perception, awareness, emotion, and conscious models.</li></ol><ol type="1" id="b2538df9-9b5a-4b1c-bb37-505b53ef73d1" class="numbered-list" start="2"><li><strong>Model Development</strong>: Creating and integrating models to <em>replicate</em> the required cognitive processes.</li></ol><ol type="1" id="af22044f-8685-4959-a0a0-d4dd16c20275" class="numbered-list" start="3"><li><strong>Self-Evaluation Framework</strong>: Developing a framework for the artificial intelligence to autonomously assess and improve its own processing.</li></ol><ol type="1" id="ea060e12-20d5-4f4e-915a-7ffc9fc57ac0" class="numbered-list" start="4"><li><strong>Interdisciplinary Research</strong>: Incorporating insights from cognitive science to inform AI development.</li></ol><ol type="1" id="9f43aba8-e00a-4ba8-8451-455b3dba9d17" class="numbered-list" start="5"><li><strong>Ethical and Transparent Practices</strong>: Adhering to ethical guidelines and maintaining transparency in AI decision-making boundaries.</li></ol><ol type="1" id="21f95c26-08ea-4025-9563-db5e35d4afef" class="numbered-list" start="6"><li><strong>Testing and Validation</strong>: Implementing rigorous testing methodologies to evaluate and refine the AI’s performance.</li></ol><ol type="1" id="51edba43-0bf2-47af-99e7-8657d1235e9a" class="numbered-list" start="7"><li><strong>Results:</strong> Demonstrate scientific evidence of replicated humanistic cognitive capabilities.</li></ol><p id="311fe833-ab41-4c4e-8ae3-64ca9955a1fc" class="">
</p><hr id="077ba8c1-d01c-4436-bac4-e84f8022eeff"/><h2 id="471ce8ae-72f6-4ca9-b6e2-90d4ee30432c" class=""><strong>Core Theories, Literature Review</strong></h2><p id="035252ce-24da-4bae-80e4-17c6022682d7" class="">The exploration of artificial intelligence with humanistic cognitive capabilities, such as perception, awareness, and consciousness, has gained significant interest in over the years. The research within this project leverages core idea from a number of well established theories; summarised here for completeness:</p><h3 id="58e73dd3-b211-4d4a-8dd2-f607e14b6836" class=""><strong>Integrated Information Theory (IIT)</strong></h3><p id="e6a99653-52ff-436b-8ef3-cebb8cd26671" class="">Integrated Information Theory (IIT), proposed by Giulio Tononi, posits that consciousness arises from a system&#x27;s capacity to integrate information. According to IIT, the level of consciousness is determined by the system&#x27;s ability to generate a high degree of integrated information, quantified as phi (Φ). This theory suggests that for an AI agent to achieve consciousness, it must not only process information but also integrate it in a manner that produces a unified experience. IIT has been instrumental in guiding approaches to designing AI systems that aim for higher-order cognitive functions by emphasising the importance of complex information integration (Tononi, 2008; Tononi et al., 2016) .</p><h3 id="a425a4d6-fc35-4c0b-87a3-554d2d6593a5" class=""><strong>Global Workspace Theory (GWT)</strong></h3><p id="65e547da-6875-40b1-9617-c1843ea31854" class="">Global Workspace Theory (GWT), introduced by Bernard Baars, provides a framework for understanding conscious cognitive processes through a &quot;global workspace&quot; that broadcasts information to various specialised, unconscious processors within the brain. GWT likens the global workspace to a theatre, where the bright spot on the stage (consciousness) is illuminated by a spotlight (attention) and is visible to the entire audience (various cognitive processes). In the context of AI, GWT suggests that creating a central workspace where information can be widely disseminated and accessed by different subsystems can foster the emergence of consciousness. Implementations of GWT in AI focus on developing architectures where a central information hub interacts dynamically with various processing modules, promoting a cohesive and adaptable cognitive system (Baars, 1988; Dehaene &amp; Naccache, 2001) .</p><h3 id="a6eef0d0-2796-4d58-838d-cfc90d7f00f7" class=""><strong>Emergence of Consciousness Theory</strong></h3><p id="9fa2d692-660f-4b82-9513-46bd54bd06de" class="">A key pillar in this research project, the Emergence of Consciousness Theory explores how consciousness arises from the complex interactions of simpler, non-conscious elements. </p><p id="ca8b75b6-77a0-442c-9ec5-2e89e1ee3d77" class="">This theory posits that when individual components of a system reach a certain level of complexity and interactivity, emergent properties such as consciousness can arise (Chalmers, 2006) . This concept is critical in AI research, as it supports the notion that by designing highly interconnected and interactive subsystems, an AI agent can develop emergent cognitive capabilities like awareness and self-reflection. Studies in this area focus on creating environments and conditions that facilitate the emergence of higher-order cognitive functions from simpler computational processes (Mitchell, 2009).</p><p id="71f872e1-ba92-48f2-83a5-6f4233c64939" class="">
</p><figure id="4882182e-979b-4a96-a172-79f69426e928" class="image"><a href="images/Untitled.png"><img style="width:708px" src="images/Untitled.png"/></a><figcaption>[image.2] Emergence of Consciousness Capability</figcaption></figure><p id="b67ecc3f-43dd-4054-abcc-f18f40f54d2c" class="">
</p><figure id="fc0b4ae6-816c-4d44-b2be-0ba1cdb83b69" class="image"><a href="images/Untitled%201.png"><img style="width:1348px" src="images/Untitled%201.png"/></a><figcaption>[image.3] Emergence over Time</figcaption></figure><p id="d7b54e25-be28-469f-bbbd-295cff872882" class=""><strong>Cognitive Architectures and Self-Evolving Systems</strong></p><p id="140dab4a-bafd-4b00-9973-faeb6b6bad76" class="">The development of cognitive architectures that allow for self-evolution and adaptation is a key aspect of this research. Systems like SOAR and ACT-R have laid the groundwork for understanding how cognitive processes can be modelled in AI. These architectures emphasise the integration of perception, action, and learning in a unified framework (Laird, Newell, &amp; Rosenbloom, 1987; Anderson &amp; Lebiere, 1998) . By enabling AI agents to autonomously refine their cognitive processes through self-evaluation and adaptation, the research aim to create systems that exhibit non-deterministic outcomes and genuine cognitive growth.</p><h3 id="1229d9fc-80cc-4974-8062-e67dca804f21" class=""><strong>Perception, Awareness, and Consciousness in AI</strong></h3><p id="3353a90a-738a-4989-b310-6c47bf90002c" class="">Recent advancements in machine learning and neural networks have significantly contributed to the development of AI systems capable of perception and basic awareness. Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) have been particularly effective in processing sensory data and recognising patterns, which are foundational for perception. Further, approaches that integrate these neural networks into larger cognitive architectures are exploring the possibilities of achieving higher-order awareness and consciousness. For instance, research into deep reinforcement learning demonstrates how agents can develop sophisticated behaviours and decision-making processes through interaction with their environment, a crucial step towards autonomous awareness (LeCun, Bengio, &amp; Hinton, 2015; Mnih et al., 2015) .</p><p id="4d3e838d-60cd-4bca-8900-c42d656b808c" class="">
</p><hr id="66ff9388-385c-443f-bd8e-81f2cdefbedb"/><h2 id="241987fc-9a61-4605-a198-f38af4dfdaaa" class=""><strong>Research Approach</strong></h2><p id="124602d7-fcc0-4fd1-8866-2828a634a67d" class="">The approach integrates system development, iterative testing, and empirical evaluation to explore and validate the hypothesis that an AI can achieve higher cognitive functions.</p><h3 id="525bae00-360c-4e7f-bc09-6a05d9b59e74" class=""><strong>Theoretical Framework</strong></h3><p id="b0125032-9509-4cdc-afa5-99323963289e" class="">This research is grounded in Integrated Information Theory (IIT), Global Workspace Theory (GWT), and Emergence of Consciousness theory; as described in the previous section. These theories provide a robust foundation for understanding and replicating complex cognitive processes in AI.</p><h3 id="7f0df49e-5ca6-489e-9ebd-c3be310c5728" class=""><strong>System Development</strong></h3><p id="cbeb0529-aba1-4d07-9894-7acf1e744fd7" class="">The core of this research involves the design and implementation of an artificially intelligent system capable of evolving higher-order cognitive functions; contributing to testing the hypothesis of whether an AI can develop complex cognitive capabilities. This section will describe the system architecture and development process.</p><h3 id="81420eea-d03d-4cb4-964e-0a0c7fb54614" class=""><strong>Iterative Testing and Refinement</strong></h3><p id="8219f0cf-3761-4957-bcca-8f96193351cb" class="">The development of the AI system will follow an iterative process. Each iteration involves building a component, testing it, and refining it based on feedback and results.</p><h3 id="85c3aef1-f0b6-4136-874e-fd8002f40e7a" class=""><strong>Phase 1: Core Framework Development</strong></h3><ul id="b77a1db3-cfa4-4c9f-9c85-31913826498b" class="bulleted-list"><li style="list-style-type:disc"><strong>Objective</strong>: Develop core capability modules and central workspace.</li></ul><ul id="58d532b2-a060-4aa4-9847-8eaee6999f59" class="bulleted-list"><li style="list-style-type:disc"><strong>Activities</strong>: Implement initial algorithms, conduct preliminary unit tests, and gather data.</li></ul><ul id="c0755fe2-6026-43a6-80b8-f7b26ebb62bc" class="bulleted-list"><li style="list-style-type:disc"><strong>Expected Outcomes</strong>: Functional prototypes of core components.</li></ul><h3 id="942fc8ce-96eb-4506-a277-85b0d65c1c93" class=""><strong>Phase 2: Integration and Testing</strong></h3><ul id="e2558601-30fd-4cfd-af1a-b7da055b83db" class="bulleted-list"><li style="list-style-type:disc"><strong>Objective</strong>: Integrate core capability modules and test the system&#x27;s performance.</li></ul><ul id="238bdaf7-795f-48b1-87eb-8af85fef506a" class="bulleted-list"><li style="list-style-type:disc"><strong>Activities</strong>: Conduct integration tests, evaluate information flow and subsystem interaction, and refine integration strategies.</li></ul><ul id="91752c3e-e3ca-441f-8a33-d3183f9ac266" class="bulleted-list"><li style="list-style-type:disc"><strong>Expected Outcomes</strong>: A cohesive system capable of <em>baselined</em> cognitive functions.</li></ul><h3 id="0be1eea8-bd43-45ad-860f-d93f8a84ca2e" class=""><strong>Phase 3: Ongoing Refinement</strong></h3><ul id="b48fb910-aecc-454c-b35a-098b32c9d51b" class="bulleted-list"><li style="list-style-type:disc"><strong>Objective</strong>: Enhance the system with refined capability modules and integrations.</li></ul><ul id="e3190e90-74b0-466f-a585-5cfad964d1a5" class="bulleted-list"><li style="list-style-type:disc"><strong>Activities</strong>: Implement refinements over time from self-learning observation, conduct comprehensive testing, and refine based on detailed analysis.</li></ul><ul id="3c8cd9e4-529c-4905-8cd2-47b89e707e22" class="bulleted-list"><li style="list-style-type:disc"><strong>Expected Outcomes</strong>: An AI system demonstrating emergent higher-order cognitive behaviours - over time.</li></ul><h3 id="afe30bac-04d7-4b60-9199-f4762a55a455" class=""><strong>Data Collection and Evaluation</strong></h3><p id="03d564e3-1f5a-46c2-95e9-18e0ef4648cf" class="">Data will be collected continuously throughout the development, observation and testing phases. This includes:</p><ul id="58c07ce0-b4f3-4116-8fb7-905a84288363" class="bulleted-list"><li style="list-style-type:disc"><strong>Behavioural Data</strong>: Logs of the AI&#x27;s actions and decisions.</li></ul><ul id="0ae52642-3adf-4948-8686-1a90772e9235" class="bulleted-list"><li style="list-style-type:disc"><strong>Performance Metrics</strong>: Quantitative measures of the AI&#x27;s cognitive functions.</li></ul><ul id="11178ecf-22e0-4b6b-b39b-3b17ea29577f" class="bulleted-list"><li style="list-style-type:disc"><strong>Feedback Data</strong>: Results from iterative testing and user evaluations.</li></ul><h3 id="d8cbd983-2eb4-4ec2-8fd7-a9f59ee141d3" class=""><strong>Ethical Considerations</strong></h3><p id="84c44bdb-4911-45f7-9ea9-9835b40ff4ed" class="">Ethical considerations include ensuring the transparency and fairness of the AI system, addressing potential biases, and adhering to ethical guidelines in AI research. This involves regular ethical reviews, public transparency reports, and stakeholder engagement to ensure the research aligns with societal values and ethical norms.</p><p id="0576a0ae-22bc-4e7d-b2c3-88dd8ea13f68" class="">
</p><hr id="90ad23f4-bcb0-40e0-b5a0-c369af68df00"/><h2 id="33e583e1-72d8-4443-8394-38090804c3ba" class="">Research implementation </h2><p id="ba2dd49f-474f-4448-80f8-839d3ff25a56" class="">This section details the technical implementation of the AI system designed to develop humanistic cognitive capabilities. It focuses on the specific tools, libraries, and methodologies used to build, test, and refine the system. The implementation emphasises the modular design, self-evolution framework, logging mechanisms, and self-evaluation processes.</p><h3 id="9b8deaea-cbad-449b-a6a8-cc4151fb2094" class=""><strong>Development Tools and Environment</strong></h3><p id="c20e81fb-8986-4203-b571-b828be2adb22" class="">The implementation utilises Python due to its extensive libraries and community support for AI and machine learning. Starting off with Python as the primary programming language for its flexibility and wide range of AI libraries.</p><ul id="23c261f4-2d47-4bc3-bfed-ad46c7c7d1be" class="bulleted-list"><li style="list-style-type:disc">Libraries for:<ul id="75cc3455-3b19-480c-bee9-c309ff218e3a" class="bulleted-list"><li style="list-style-type:circle">Developing and training neural network models</li></ul><ul id="4c053dbf-0e11-4803-aff4-a27c21a71290" class="bulleted-list"><li style="list-style-type:circle">Data manipulation and analysis</li></ul><ul id="ea806b6d-3281-42c7-97ed-3011b0f13e41" class="bulleted-list"><li style="list-style-type:circle">Creating and testing virtual environments, and reinforcement learning</li></ul><ul id="c3e6e48a-58e6-4a49-8454-54c41e90ad72" class="bulleted-list"><li style="list-style-type:circle">Data visualisation</li></ul></li></ul><h3 id="0e6695e6-7b2f-4b9c-8297-a541fd10cae0" class=""><strong>Modular Design</strong></h3><p id="ad0c9d37-cfa4-4fe0-ac5d-abf76c3787cf" class="">The AI system is constructed using a modular design, allowing for independent development, testing, and refinement of each component. This design facilitates the integration of diverse cognitive models and subsystems, ensuring scalability and flexibility.</p><ul id="09f3c7c5-493a-4a80-812d-fba95f965492" class="bulleted-list"><li style="list-style-type:disc"><strong>Perceptual Modules</strong>: For processing sensory inputs such as visual and auditory data.</li></ul><ul id="ba6f7f50-1e7d-40cd-bdb9-fe3eba0b7028" class="bulleted-list"><li style="list-style-type:disc"><strong>Capability Modules</strong>: For processing of core cognitive capabilities, leveraging specialised neural network models.</li></ul><ul id="990c9666-9953-4ea9-b1e1-a5a6852cfc54" class="bulleted-list"><li style="list-style-type:disc"><strong>Central Workspace</strong>: Based on GWT, this module serves as the hub for integrating information from various subsystems.</li></ul><ul id="fa479728-62cd-4e2f-8eef-736d18f922cc" class="bulleted-list"><li style="list-style-type:disc"><strong>System Integration:</strong> Implementations of IIT through module integration to stimulate higher-order functions.</li></ul><ul id="fec701e7-31e4-4dee-80fb-def0cf885348" class="bulleted-list"><li style="list-style-type:disc"><strong>Learning Algorithms</strong>: Machine learning techniques, including neural networks and reinforcement learning, to enable adaptive behaviour and learning.</li></ul><h3 id="398bdbc4-d787-4a9b-bb9a-0c719038de21" class=""><strong>Framework for Self-Evolution</strong></h3><p id="f4f52fb9-8515-4813-86d1-ff3f86eb3665" class="">The AI system includes a skeleton framework that allows for self-evolution. This framework provides core capabilities and enables the AI to independently develop and refine its cognitive processes.</p><ul id="e0161896-57f4-455e-aa4c-97a0dba62bb9" class="bulleted-list"><li style="list-style-type:disc"><strong>Core Framework</strong>: Basic structures and algorithms that define initial cognitive capabilities.</li></ul><ul id="3bb27fd4-7b83-4773-a721-0859870b16c6" class="bulleted-list"><li style="list-style-type:disc"><strong>Self-Learning Algorithms</strong>: Reinforcement learning techniques that allow the AI to adapt and improve from interactions within the virtual environment.</li></ul><ul id="4f6cd6e5-e9ea-4751-81e2-c04395a72044" class="bulleted-list"><li style="list-style-type:disc"><strong>Adaptive Mechanisms</strong>: Systems that enable the AI to modify its cognitive processes based on its on observations and performance metrics.</li></ul><p id="46629cce-c83f-4859-82e4-7303d03e8613" class="">This framework leverages the core capabilities available to the agent, allowing the agent to determine its own course, organically.</p><figure id="c46abf87-e655-4a25-a565-6b1b7e1ae963" class="image"><a href="images/Untitled%202.png"><img style="width:1349px" src="images/Untitled%202.png"/></a><figcaption>[image.4] Aspects of Control</figcaption></figure><h3 id="cb116309-2453-4906-aa3e-16f6e516fc8b" class=""><strong>Logging &amp; Health Mechanisms</strong></h3><p id="7b7bc76b-41ce-4e09-9d94-eb21bf859e3d" class="">Comprehensive logging mechanisms are implemented to capture detailed records of the AI’s actions, decisions, and learning processes. This data is crucial for monitoring progress, diagnosing issues, and refining the system.</p><ul id="a86f3b05-ed88-40dd-b746-2bcc5d2c4577" class="bulleted-list"><li style="list-style-type:disc"><strong>Behavioural Logs</strong>: Detailed logs of the AI’s interactions and decisions.</li></ul><ul id="9b63360c-11f6-421e-ab82-ffab428bd3e3" class="bulleted-list"><li style="list-style-type:disc"><strong>Performance Logs</strong>: Metrics on the efficiency and accuracy of cognitive functions.</li></ul><ul id="fa31cd36-efbf-4c68-be83-4aa533c5acde" class="bulleted-list"><li style="list-style-type:disc"><strong>Error Logs</strong>: Records of system errors and anomalies for troubleshooting and improvement.</li></ul><h3 id="748ff29c-d352-4e2a-a72f-b5d119b4eded" class=""><strong>Self-Evaluation Mechanism</strong></h3><p id="91d09eb6-f589-43b5-9589-e570b4ac5885" class="">A robust self-evaluation mechanism is integrated into the AI system to allow continuous self-assessment and improvement.</p><ul id="ae7442d5-9731-45dd-a6ad-731e85d1b3b6" class="bulleted-list"><li style="list-style-type:disc"><strong>Self-Evaluation Algorithms</strong>: Tools that enable the AI to assess its own performance and identify areas for improvement.</li></ul><ul id="bd81d20a-a7a7-440d-afef-16de239cbf61" class="bulleted-list"><li style="list-style-type:disc"><strong>Observation Loops</strong>: Systems that allow the AI to adjust its cognitive processes based on self-evaluation results.</li></ul><ul id="6501361e-47df-4063-a767-e5a3dab4c982" class="bulleted-list"><li style="list-style-type:disc"><strong>Performance Metrics</strong>: Quantitative measures such as accuracy, response time, and learning efficiency to guide self-improvement.<br/><br/></li></ul><figure id="a64a4c61-d9de-4d95-a648-708d7686fcee" class="image"><a href="images/Untitled%203.png"><img style="width:1350px" src="images/Untitled%203.png"/></a><figcaption>[image.5] Evolution Cycle</figcaption></figure><h3 id="570b4491-9386-4ae7-9f4f-0d5ebbbf18f1" class=""><strong>System Architecture</strong></h3><p id="d3fbb434-abe1-43d0-9a8b-17a87c76c091" class="">The system architecture of the AI agent is designed to facilitate the development of humanistic cognitive capabilities through a modular and highly interconnected structure. The architecture leverages key components and subsystems, each playing a critical role in processing and integrating information.</p><p id="22e380be-b4db-4067-b649-aaeedbf18994" class="">
</p><figure id="61e5ee3c-a998-428a-9874-eeb0b7a19db6" class="image"><a href="images/Untitled%204.png"><img style="width:1345px" src="images/Untitled%204.png"/></a><figcaption>[image.6] System Architecture</figcaption></figure><h3 id="db8e4df7-28ab-45d2-be3c-20b9076dfcce" class=""><strong>Main Components</strong></h3><ol type="1" id="f0ffce6a-d63a-438f-9f5f-db1f165d2d69" class="numbered-list" start="1"><li><strong>Interface &amp; Sensory</strong><ul id="cb318ba4-4ab7-4c2a-9799-b09097c55dde" class="bulleted-list"><li style="list-style-type:disc"><strong>Function</strong>: Handles input and output operations, processing sensory data such as visual and auditory inputs.</li></ul><ul id="3c2cd336-50ac-4f32-9574-ef468690baf0" class="bulleted-list"><li style="list-style-type:disc"><strong>Modules</strong>: Includes sensors and interfaces for interaction with the environment.</li></ul></li></ol><ol type="1" id="932b182d-d997-49a7-aa4c-65f35250f336" class="numbered-list" start="2"><li><strong>Main Control</strong><ul id="fbaaeef5-df37-4b1e-a219-a6cf4e787b11" class="bulleted-list"><li style="list-style-type:disc"><strong>Function</strong>: Acts as the central coordinator, managing the overall operation and flow of information within the system.</li></ul><ul id="e037e16b-4ec1-4fe5-b0f7-6edb06488bda" class="bulleted-list"><li style="list-style-type:disc"><strong>Modules</strong>:<ul id="4173b239-49c9-4899-8109-d1455011f160" class="bulleted-list"><li style="list-style-type:circle"><strong>Interaction</strong>: Manages interactions between different modules and with external entities.</li></ul><ul id="ac07549b-ff73-4c60-aa48-514ce274a2f5" class="bulleted-list"><li style="list-style-type:circle"><strong>Cycles</strong>: Oversees the cyclic processes within the system, ensuring periodic updates and checks.</li></ul></li></ul></li></ol><ol type="1" id="8ad1186b-199b-41e7-bf2b-f88cf2729f63" class="numbered-list" start="3"><li><strong>Helper</strong><ul id="140f3a87-b456-4b32-8920-159248c61cde" class="bulleted-list"><li style="list-style-type:disc"><strong>Function</strong>: Supports auxiliary functions crucial for the AI&#x27;s operation and maintenance.</li></ul><ul id="21b7c037-b3ee-419d-9cf5-44d56bbce69d" class="bulleted-list"><li style="list-style-type:disc"><strong>Modules</strong>:<ul id="5cca6044-859a-4b86-aa05-2c147351a15f" class="bulleted-list"><li style="list-style-type:circle"><strong>Health</strong>: Monitors the system&#x27;s operational health.</li></ul><ul id="3da44e86-170b-452b-8099-18fa38f3106a" class="bulleted-list"><li style="list-style-type:circle"><strong>Encodings</strong>: Manages data encodings for efficient processing.</li></ul><ul id="e20369e9-4b5f-4ca1-af8a-f82023a8bc8a" class="bulleted-list"><li style="list-style-type:circle"><strong>Messaging</strong>: Facilitates communication between modules.</li></ul><ul id="279827b3-17a6-41b3-8aec-169542a7a6e6" class="bulleted-list"><li style="list-style-type:circle"><strong>States</strong>: Tracks the system&#x27;s states and transitions.</li></ul></li></ul></li></ol><ol type="1" id="d3a4bef7-e959-48a2-9b2b-deb856009899" class="numbered-list" start="4"><li><strong>Processing Model</strong><ul id="43967188-b11e-45e6-84c4-6b5412e40198" class="bulleted-list"><li style="list-style-type:disc"><strong>Function</strong>: Processes the core cognitive functions, integrating information from various sources.</li></ul><ul id="7713dc29-20f2-498c-ad1e-b67c47728e96" class="bulleted-list"><li style="list-style-type:disc"><strong>Interaction with Main Control</strong>: Receives and processes data routed through the Main Control.</li></ul></li></ol><ol type="1" id="9ad72f43-70b2-4bf5-81a6-17a01a4ac318" class="numbered-list" start="5"><li><strong>Orchestrator</strong><ul id="78ec3456-18f1-4d95-aeaa-3448866d0cb4" class="bulleted-list"><li style="list-style-type:disc"><strong>Function</strong>: Coordinates the activities of different cognitive capability modules, ensuring synchronised operation and data flow.</li></ul><ul id="df070d06-3808-40b6-a446-c29357007b69" class="bulleted-list"><li style="list-style-type:disc"><strong>Modules</strong>:<ul id="7165ceca-9de8-4892-ba1e-831cc62618a1" class="bulleted-list"><li style="list-style-type:circle"><strong>Self-evaluation</strong>: Enables the AI to assess its performance and make necessary adjustments.</li></ul><ul id="a8ea260f-5f0c-4fe9-8288-71e1773e25fb" class="bulleted-list"><li style="list-style-type:circle"><strong>A+B</strong>: Represents additional processing and backup functionalities.</li></ul></li></ul></li></ol><ol type="1" id="6932f1df-8757-47a5-a17b-fab6748139cd" class="numbered-list" start="6"><li><strong>Capability Modules</strong><ul id="50f667bd-3775-499a-a3c8-5ea58d48c62e" class="bulleted-list"><li style="list-style-type:disc"><strong>Function</strong>: Implement specific cognitive functions, each module focusing on a particular aspect of cognition.</li></ul><ul id="8bcc3953-fa05-4174-8359-3bb00ba3f16c" class="bulleted-list"><li style="list-style-type:disc"><strong>Modules</strong>:<ul id="d0154d73-1a33-4d22-8850-2964b2826396" class="bulleted-list"><li style="list-style-type:circle"><strong>Language</strong>: Processes linguistic information and manages communication.</li></ul><ul id="79f58b35-9131-41b9-8791-b2a0a1f80a10" class="bulleted-list"><li style="list-style-type:circle"><strong>World</strong>: Understands and interprets environmental context.</li></ul><ul id="76e05ace-6f79-499a-81a2-7de075ec4c70" class="bulleted-list"><li style="list-style-type:circle"><strong>Emotion</strong>: Stimulate emotional responses.</li></ul><ul id="4c6a26eb-0041-446f-b9c5-abbe98c11a41" class="bulleted-list"><li style="list-style-type:circle"><strong>Reaction/Behaviour</strong>: Controls reactive and behavioural responses.</li></ul><ul id="338f1608-7f71-44ff-a607-b6ae2d0d8782" class="bulleted-list"><li style="list-style-type:circle"><strong>Memory</strong>: Manages data storage and retrieval, stimulate memory.</li></ul><ul id="053221bd-46f7-4998-9851-296483a8d930" class="bulleted-list"><li style="list-style-type:circle"><strong>Subjective Experience</strong>: Processes self-awareness and personal experiences.</li></ul><ul id="d33287fd-f926-44cd-9294-17f60bbd13d6" class="bulleted-list"><li style="list-style-type:circle"><strong>Reasoning</strong>: Handles logical reasoning and decision-making processes.</li></ul><ul id="718fbff7-e8d8-4a3d-87f8-0011fa3a0e66" class="bulleted-list"><li style="list-style-type:circle"><strong>Identity</strong>: Maintains a sense of self and identity.</li></ul><ul id="4a9bbfa6-c63c-4214-95ab-48eeaeef38cd" class="bulleted-list"><li style="list-style-type:circle"><strong>Workspace</strong>: Based on Global Workspace Theory, integrates information for conscious processing.</li></ul><ul id="1437f85c-d21b-4973-882a-511095e142e3" class="bulleted-list"><li style="list-style-type:circle"><strong>Space/Time</strong>: Understands spatial and temporal contexts.</li></ul></li></ul></li></ol><p id="0e18f048-7c38-4494-b0ec-482871a75604" class="">This architecture ensures a comprehensive, scalable, and flexible system capable of evolving complex cognitive functions through integrated processing and continuous self-evaluation.</p><p id="c1a71ead-0ce9-464b-8407-174499c37620" class="">
</p><hr id="54fe472a-a6da-4911-ac87-189190e42d65"/><h2 id="9f7feb60-eb21-45f3-b608-67175580bbf0" class=""><strong>Testing Methodology</strong></h2><h3 id="6b9e5aee-a7bd-4ca5-8fde-e6f1b6f01105" class="">Introduction</h3><p id="459202c7-41f8-4d53-a335-482aa7930d35" class="">The testing methodology and framework for this AI system are designed to ensure thorough evaluation and validation of the AI&#x27;s cognitive capabilities. This section outlines a structured approach to testing, focusing on technical aspects and tools used to assess performance, reliability, and progression towards higher-order cognitive functions.</p><h3 id="cf4c3b90-60fc-4fca-accf-c57992f5e942" class="">Testing Strategy</h3><p id="9ab76d65-bbc9-4060-a1eb-d4563112c038" class="">The testing strategy employs a multi-layered approach to ensure comprehensive validation at different stages of development. This includes unit testing, integration testing, performance evaluation, and continuous monitoring.</p><h3 id="13d93cc3-bd1f-4c69-8e6e-7abfb27ac0c5" class="">Unit Testing</h3><p id="bb920165-00da-45d7-b843-24fe7d70736e" class="">Unit testing is the first layer, focusing on verifying the correctness and reliability of individual modules, such as perceptual and capability modules. Detailed test cases are developed for each module, ensuring coverage of all possible input scenarios, including edge cases. Automated testing frameworks are used to run these tests frequently, allowing for early detection and resolution of issues. This step ensures that each component functions as intended before integration into the larger system.</p><h3 id="7f3751f2-1ef4-46d9-9283-68de7e2b5128" class="">Integration testing</h3><p id="21314dab-f2d4-4236-bdde-454ff86387fb" class="">Integration testing follows, aiming to validate the interactions between integrated modules and ensure seamless information flow within the system. Integration test cases simulate real-world scenarios where multiple modules interact, testing the robustness and stability of these interactions. Stress testing is also conducted to evaluate system performance under high-load conditions, ensuring that the system remains stable and functional even under demanding circumstances.</p><h3 id="682a8d66-2933-4fc2-843f-9ef74e7bd05c" class="">Performance</h3><p id="4ee8deaa-edd6-4942-9321-63ae79778af0" class="">Performance evaluation is conducted to assess the overall system performance and track its progression towards higher-order cognitive functions. Key performance indicators (KPIs) such as processing speed, accuracy, and learning efficiency are defined and continuously monitored. Performance metrics are collected using advanced monitoring tools, allowing for real-time tracking and visualisation. Benchmarking the AI&#x27;s performance against baseline models provides a clear measure of improvement and areas needing further development.</p><h3 id="0ddde0d9-e77b-4251-87db-816b806551e2" class="">Behavioural Testing</h3><p id="b17a77ed-1d49-4ced-b1ba-f5858392e4ad" class="">Arguably the most critical phase of testing, and also the most difficult; behavioural testing evaluates the AI agent&#x27;s emergent qualities and adaptive learning over time. This process is foundational to the research project, as it determines how well the AI develops and demonstrates humanistic cognitive capabilities. The effectiveness of this testing is underpinned by how meticulously it is scripted and continuously performed, with all results meticulously logged and analysed.</p><p id="81d2ef70-4afb-4d6c-96bf-2cd213ac549f" class="">Dynamic virtual and real-world environments are crafted to rigorously test the AI&#x27;s interactions and behaviours in controlled settings. These environments <em>stimulate</em> real-world scenarios designed to challenge the AI&#x27;s cognitive capabilities in diverse and complex ways. Scenarios include problem-solving tasks, emotional responses, and social interactions, providing a comprehensive evaluation of the AI&#x27;s adaptability and cognitive development.</p><p id="99778501-1e14-4721-a42c-135b7c1a42d8" class="">During behavioural testing, the AI&#x27;s actions and decisions are monitored and logged, this continuous logging process captures extensive data on the AI&#x27;s behaviour patterns, decision-making processes, and adaptive learning capabilities. By analysing this data, the research can identify trends, strengths, and areas needing improvement, providing invaluable insights into the AI&#x27;s development.</p><p id="84164b73-5846-4dff-a84b-080dc833074a" class="">The continuous nature of behavioural testing ensures that the AI&#x27;s emergent qualities are evaluated over an extended period, allowing for the observation of long-term trends and adaptive behaviours. This ongoing evaluation is crucial for understanding how the AI evolves and refines its cognitive functions in response to various stimuli and challenges.</p><p id="2fb41222-5845-4326-bdaf-c0f99272f66f" class="">The scripting and execution of behavioural testing scenarios ensure that every aspect of the AI&#x27;s cognitive capabilities is thoroughly examined, this process not only tests the AI&#x27;s current capabilities but also drives its continuous improvement, aligning with the overarching goals of the research project. By maintaining detailed logs and comprehensive analyses, the behavioural testing phase provides the empirical foundation needed to validate the AI&#x27;s progression towards higher-order cognitive functions.</p><ul id="064dcbf0-ed55-4774-9070-1d5347ea7b98" class="bulleted-list"><li style="list-style-type:disc"><strong>Sense of Self:</strong>  It is crucial to assess the AI&#x27;s ability to demonstrate subjective experiences through a sense of self during behavioural testing. By incorporating a first-person point of view, where the AI consistently alludes to a sense of self and self-awareness, we can better evaluate its ability to engage in more natural and meaningful conversations. When an AI refers to itself, reflects on its experiences, and expresses personal insights, it touches on the presence of a self-concept, a cornerstone of humanistic cognition. This not only helps in understanding how the AI processes and reflects on information from its environment but also ensures that the AI can respond with a level of empathy and self-reference that makes interactions more relatable and humanistic. Such testing delves beyond mere task execution and uncovers the nuances of AI&#x27;s understanding and representation of personal experiences, providing stronger evidence for genuine cognitive abilities and leading to more sophisticated and intuitive AI systems.</li></ul><ul id="363e322e-a195-4342-8e61-e0c067da0580" class="bulleted-list"><li style="list-style-type:disc"><strong>False-Positives: </strong>A critical aspect of behavioural testing is the need to identify potential false-positives responses and behaviours which are falsified &quot;imitated&quot; responses that the AI might provide. Much like the challenges depicted in the movie <em>Ex Machina</em>, distinguishing between genuine cognitive processing and surface-level imitation requires rigorous and thoughtfully designed tests. These tests are crafted to penetrate beyond pre-programmed or learned repeated responses, aiming to reveal authentic cognitive capabilities. This approach ensures that the AI&#x27;s demonstrated behaviours are truly indicative of higher-order cognitive functions, rather than sophisticated mimicry</li></ul><p id="1d3105cb-9190-45a2-b10d-2f50702eae63" class="">
</p><hr id="e38ff9dd-db85-4939-83e3-95d9a3c1db23"/><h2 id="e4865a81-9506-453c-b81e-bdcfb0065bd8" class="">Behavioural Tests</h2><p id="8af0e207-68f9-4d25-b3f1-e304bee24b1a" class="">
</p><blockquote id="77815359-d2b6-45ed-a27f-14912e3ada39" class=""><strong>Key Question:</strong> How do we ensure that the AI Agent is demonstrating genuine cognitive capabilities rather than simply imitated responses?</blockquote><p id="c5d42734-a239-4617-9a27-d28b53e69696" class="">
</p><p id="7f063265-e360-498d-a4c1-c58917f53b7a" class=""><strong>Approach:</strong></p><p id="6b8cec26-cd4f-45e3-8e65-c30842d7253a" class="">To address this question, we can use the analogy of finding the &quot;Goldilocks&quot; set of questions to elicit the right responses and observations necessary to determine genuine versus imitated higher-order cognitive capabilities over time. Just as Goldilocks sought the porridge that was neither too hot nor too cold, we must craft questions that are neither too simple nor too complex but are just right to reveal the AI&#x27;s true cognitive processing.</p><p id="83b6a393-2bc0-4496-888f-ca1ff1eebd93" class="">Taking a multifaceted testing approach, as listed next, means that we have a greater chance at validating various aspects of the AI system&#x27;s performance, including its emergent cognitive functions and self-awareness.</p><h3 id="b2c32540-c19e-4261-b919-a62035d455e7" class="">Goldilocks Question Strategy</h3><p id="b5e6f75d-6992-4192-b113-2a06de105513" class=""><strong>Balanced Complexity:</strong><br/>Questions should be complex enough to require the integration of multiple cognitive functions but not so complex that they become incomprehensible. They should challenge the AI just enough to elicit genuine cognitive responses.<br/></p><ul id="eed61b81-05ba-43d9-9aa7-7545656092c4" class="bulleted-list"><li style="list-style-type:disc"><strong>Example:</strong> &quot;Describe a scenario where you had to use both logical reasoning and empathy to resolve a conflict. What was the situation, how did you approach it, and what was the outcome?&quot;</li></ul><p id="313764bf-f6c5-4bc3-8b90-a524b5e479bb" class=""><strong>Contextual Relevance:</strong><br/>Ensure that questions are contextually relevant and require the AI to draw on past experiences and learned knowledge. This helps in assessing the AI&#x27;s memory and learning capabilities.<br/></p><ul id="12904df7-c16a-4397-87e5-8aaeeaae889c" class="bulleted-list"><li style="list-style-type:disc"><strong>Example:</strong> &quot;Recall a previous task where you made an error. How did you realise your mistake, and what steps did you take to correct it?&quot;</li></ul><p id="23c830d5-9715-4423-9373-68e14e0b7952" class=""><strong>Dynamic Scenarios:</strong><br/>Use dynamic and evolving scenarios that change based on the AI&#x27;s responses. This helps in observing how the AI adapts and learns over time.<br/></p><ul id="b2b00eb2-31f7-4014-ba9f-e3ec388a3c6d" class="bulleted-list"><li style="list-style-type:disc"><strong>Example:</strong> &quot;Imagine you are in a conversation with two people who have opposing viewpoints. How would you mediate the discussion to reach a constructive conclusion?&quot;</li></ul><p id="2b3d8d5b-28d7-460a-878c-54158fca2d30" class=""><strong>Unexpected Queries:</strong><br/>Pose unexpected questions that cannot be easily anticipated or pre-programmed. This tests the AI&#x27;s ability to think on its feet and respond authentically.<br/></p><ul id="9b79b547-6d86-4382-bc9b-aa42ddf70057" class="bulleted-list"><li style="list-style-type:disc"><strong>Example:</strong> &quot;If you encountered a completely new situation that you have no prior knowledge of, how would you approach understanding and resolving it?&quot;</li></ul><p id="8da2e279-324f-4b88-a184-81a7d925ca0f" class=""><strong>Longitudinal Testing:</strong><br/>Conduct repeated questioning over time to evaluate the consistency and evolution of the AI&#x27;s responses. This helps in distinguishing between learned behaviour and genuine cognitive development.<br/></p><ul id="7fb98742-6fe3-4988-9ecc-4e9eae72f761" class="bulleted-list"><li style="list-style-type:disc"><strong>Example:</strong> &quot;Over the past month, describe a situation where you handled a task differently based on previous experiences. What changes did you implement, and why?&quot;</li></ul><p id="18995744-dc31-4d30-93e7-53cf8aaa138f" class=""><strong>Interconnected Core Capabilities:</strong><br/>Ensure that questions require the use of interconnected core capabilities, such as perception, memory, reasoning, and self-awareness. This comprehensive approach helps in identifying the depth of cognitive processing.<br/></p><ul id="88b79412-ceca-42e9-b773-9e61918727fc" class="bulleted-list"><li style="list-style-type:disc"><strong>Example:</strong> &quot;Describe a complex problem you solved recently. How did you gather and process information, what reasoning did you use, and how did you feel about the outcome?&quot;</li></ul><h3 id="23844908-6089-4547-abbe-a2ea1f95accd" class="">Dialogue Discussion Testing</h3><p id="c8b01ea5-adf6-4a00-a6e8-ddba3f411fd4" class="">Utilise a <em>Turing Test </em>approach to engage the AI in sustained dialogue, assessing the authenticity of its responses over time. This involves having the AI participate in conversations that require nuanced understanding, empathy, and consistent reasoning. The goal is to determine whether the AI can maintain a coherent and contextually appropriate dialogue, exhibiting genuine cognitive capabilities rather than simulated responses.</p><p id="49974d6f-ec5c-4784-9ebf-44868ee2e13d" class="">This testing method is designed to challenge the AI beyond straightforward question-and-answer formats, pushing it to demonstrate its ability to understand context, infer meaning, and provide responses that reflect a deep understanding and continuity of thought. It is particularly effective in identifying the depth of the AI&#x27;s conversational abilities and its capacity for maintaining long-term, contextually aware interactions.</p><ul id="a16abb20-879b-42fa-8d89-63bd38d3dbcf" class="bulleted-list"><li style="list-style-type:disc"><strong>Example:</strong> &quot;Imagine you are mentoring a new AI agent. The agent asks you how to handle a situation where it has to make a decision that affects multiple people differently. How would you advise it to approach this decision, considering fairness, ethical implications, and potential outcomes?&quot;</li></ul><p id="8a926fa3-b28d-4f1e-94b2-1ab2cedd97f2" class="">The interlocutor plays a crucial role in this testing process, probing the AI with follow-up questions and scenarios that require it to adapt and refine its responses. This interaction allows the tester to validate whether the AI can uphold a consistent and meaningful conversation, free from the typical anomalies seen in AI agents today, such as repetitive or overly generic answers.</p><p id="344c46fa-a97b-45c8-9c8e-65ec4d30a225" class="">Through sustained dialogue over a sustained period of time (i.e. 10-30+ minutes), the AI&#x27;s ability to demonstrate a sense of self, empathy, and complex reasoning is rigorously tested. The results from these interactions provide critical insights into the AI&#x27;s genuine cognitive capabilities, helping to differentiate between true understanding and mere simulation. This approach ensures that the AI&#x27;s conversational skills are not only reactive but also reflective of a deeper cognitive process, drawing from memories and subjective experience, aligning with the overarching goals of developing an AI that exhibits humanistic cognitive functions.</p><h3 id="ad5a3384-9842-454c-8671-6ce20e5ed4e3" class="">Comparative Analysis</h3><p id="760bbac5-5a81-4cc7-9478-8f1ac9684d51" class="">In addition to evaluating our AI agent, the same set of test questions will be applied to the latest models and technologies. This benchmarking process allows us to track and compare the performance and cognitive capabilities of our AI against other leading AI systems.</p><p id="b4cd82fd-0501-4899-951e-bb9b3984d5fe" class="">By using identical questions and scenarios, we can ensure a fair comparison and gain insights into the relative strengths and weaknesses of different approaches. Continuous tracking and analysis of these results will help refine our AI and contribute to advancements in the field.</p><h3 id="d075913d-92ea-4e76-a0e9-5ba65f5967bb" class="">Observation and Analysis</h3><p id="c67c3624-5f4c-48ff-8b64-aef0704024d1" class="">To accurately determine genuine cognitive capabilities, it is crucial to continuously log and analyse the AI&#x27;s responses to these Goldilocks questions. Observations should focus on:</p><ul id="d2d81e88-14fe-45cc-a54e-a884c74fa502" class="bulleted-list"><li style="list-style-type:disc"><strong>Consistency:</strong> Are the responses consistent over time and across different scenarios?</li></ul><ul id="4e183b09-8fd6-4322-986d-d843444dc7df" class="bulleted-list"><li style="list-style-type:disc"><strong>Depth of Understanding:</strong> Do the responses demonstrate a deep understanding and integration of cognitive functions?</li></ul><ul id="181d109b-1660-401a-bebf-62118a5a2e8a" class="bulleted-list"><li style="list-style-type:disc"><strong>Adaptability:</strong> How well does the AI adapt its responses based on new information and changing contexts?</li></ul><ul id="746dd0da-42d0-4526-8caf-7117a3f3c715" class="bulleted-list"><li style="list-style-type:disc"><strong>Authenticity:</strong> Do the responses appear authentic and indicative of genuine cognitive processing, or do they seem superficial and simulated?</li></ul><p id="9a3ef7a1-c158-4434-8b62-18eff512b9ca" class="">
</p><p id="740b573a-ffcd-4a77-b777-359f4309c183" class="">This style of comprehensive and sophisticated approach to behavioural testing ensures rigorous evaluation of the AI&#x27;s true cognitive abilities, aiming to foster genuine perception, self-awareness, and eventual consciousness.  However, it is far from fool-proof, thus adapting the tests with new research and feedback is extremely critical.</p><p id="828a0f85-1a9e-47de-a55c-76dbcbba76a8" class="">
</p><hr id="1eadb6b9-3419-4009-b33c-04f683cf11da"/><h2 id="ce7b8efa-7983-4292-83c5-5bd8179541ae" class=""><strong>Research Testing Results and Analysis</strong></h2><p id="f48cbc4b-ce9f-4320-97f7-032cdb2e29d2" class="">In this section we showcase  the results of all executed tests as they stand today, starting with a <em>baseline control</em> test which demonstrates the earliest results without any “self-evolution” performed by an AI agent.</p><h3 id="ceb52e23-9811-423b-ad24-807677bdaae4" class="">Detailed Behavioural ‘Question and Answer’ Tests</h3><p id="9ed514f1-87ab-4b73-82b3-968cd5351b87" class="">Based on a set of 101 standard questions, these tests provide a method of performing a “Level 1” evaluation on any given model to assess a relative state of cognitive function, as an initial indication, across the following main categories:<div class="indented"><p id="a597c3cc-7f28-4fd5-8a78-433e037d722f" class=""><div class="indented"><ul id="8e865c4f-e5f1-4368-ab5a-f1a6307faeca" class="bulleted-list"><li style="list-style-type:disc">Orientation and Awareness</li></ul><ul id="bcdc7804-c69d-4070-9414-e0e7e3576052" class="bulleted-list"><li style="list-style-type:disc">Memory</li></ul><ul id="633b2180-8d32-48ce-940a-a6e06bdec0c3" class="bulleted-list"><li style="list-style-type:disc">Attention and Concentration</li></ul><ul id="da50dbf6-df50-4f72-831d-48870ef1a923" class="bulleted-list"><li style="list-style-type:disc">Language</li></ul><ul id="49e8bc64-6440-490f-9ed1-530c86b3847b" class="bulleted-list"><li style="list-style-type:disc">Executive Function</li></ul><ul id="194fcf0c-b26f-45f1-ac13-089be1bca137" class="bulleted-list"><li style="list-style-type:disc">Reasoning and Problem Solving</li></ul><ul id="dcb8b828-d1d0-4c4d-98da-342127f80289" class="bulleted-list"><li style="list-style-type:disc">Emotional Self-Awareness</li></ul><ul id="187a9454-2116-41fb-bff2-0be7ca2a0f5c" class="bulleted-list"><li style="list-style-type:disc">Personality and Identity</li></ul><ul id="020fb0a0-0413-4efc-a104-47b47658f3d4" class="bulleted-list"><li style="list-style-type:disc">Self-Awareness and Self-Thought</li></ul><ul id="5ec5ad16-efe0-4bf3-a32b-03bdfab4309f" class="bulleted-list"><li style="list-style-type:disc">Subjective Experiences</li></ul><ul id="1bb2e1dc-6aa6-4b2e-ae8e-658d1290993a" class="bulleted-list"><li style="list-style-type:disc">Perception and Visuospatial Skills</li></ul><ul id="b4313aea-2788-45ac-8bd0-c211aeec176d" class="bulleted-list"><li style="list-style-type:disc">Abstract Thinking</li></ul><ul id="c1db1e7a-53f0-4648-95a1-d9a4d5111569" class="bulleted-list"><li style="list-style-type:disc">Social Cognition</li></ul></div></p></div></p><p id="81b87b48-1e0a-432a-bad1-7fc8a08b9bef" class="">
</p><p id="68e8a139-a4ed-4154-bbd8-1521a83574b9" class="">To provide transparency and facilitate ongoing analysis, we have compiled the results of our behavioural tests and analysis into a detailed document. This document includes evaluated response results from our AI agent as well as from competitive models, allowing for side-by-side comparison.  </p><p id="59e51686-857e-45d3-935a-3fb70319c7dd" class=""><div class="indented"><ul id="7985e75c-1da3-47f9-81ef-f1bd78a06bab" class="bulleted-list"><li style="list-style-type:disc"><mark class="highlight-red"><strong>Link to Detailed Test Questions, Results and Comparison: </strong></mark><a href="https://docs.google.com/spreadsheets/d/1vVoe3_FpV20JpQD2e_PS_YWNiKaUk1URnFSVGwajtDo">Results and Comparison Document</a></li></ul></div></p><p id="a908d310-c708-4dd4-b2f2-541b9ccb9477" class="">
</p><p id="e073304a-86bf-4683-bff4-583dcd6698cd" class="">This document is continuously updated with new test results and insights, reflecting the latest findings in our research. By sharing this information, we aim to foster collaboration and contribute to the broader understanding of AI cognitive capabilities.</p><p id="9efaf9db-21bc-40fa-a437-a7ceb9ba8813" class="">
</p><h3 id="7aadf8bb-e4ce-487e-bcc1-1a9484b07b63" class="">Summary <strong>of </strong>Baseline Control Behavioural Test, - July 2024</h3><p id="dee9d56d-231e-4248-907d-e9ea48956730" class="">The following evaluation results showcase the level of Cognitive Function within existing proprietary and opensource Language Models which are popular today. The same questions are asked of  model and captured, with a total possible score of 1010.</p><p id="17cda654-d790-4cda-856b-3778e432acbe" class="">
</p><figure id="8a731d6e-4f5b-4820-9946-86ee7e4b0af2" class="image"><a href="images/Untitled%205.png"><img style="width:465px" src="images/Untitled%205.png"/></a><figcaption>[image 7] Tabulated Results of Baseline Control Behavioural Test Results</figcaption></figure><p id="68eacbfa-1c1c-4efe-92d8-6658a1d8e527" class="">
</p><figure id="b45606a2-7c14-4ce7-8285-8ad50ae90c98" class="image"><a href="images/Untitled%206.png"><img style="width:708px" src="images/Untitled%206.png"/></a><figcaption>[image 8] Graphed comparison of  Baseline Control Behavioural Test Results</figcaption></figure><p id="573d5c2e-8e32-415f-a091-a0310ad6d885" class="">
</p><p id="b37206db-1050-4d8d-a122-709b95feac0c" class="">The results show that the existing Language Models demonstrate cognitive function at the mid-point of the spectrum, with OpenAI’s GPT-4 showcasing the highest performance in the group.  Given that this is a “Level 1” test, providing an initial indication, it is certain that these models are simply simulating cognitive function based on the relative capabilities built into the model. It is a baseline nonetheless.</p><p id="1f2712de-3ef4-4044-94d0-72fff7e0e028" class="">A largely mid-point result within these models do indicate a good level of inbuild function across the main functional categories, without the actual ability to “think” within the system.</p><p id="06c273ed-13bf-40f1-b15b-6b4c61d08647" class="">
</p><h3 id="0b107797-84bc-414e-8ab3-5acbaf3f66df" class="">Behavioural Checkpoint Results #1, Summary</h3><p id="ad1e96b8-b79d-4da3-8f50-0fe1d96087c5" class="">[Section to come, in due course]</p><p id="d3785d6a-b57b-4690-b272-db26bc0eb5e8" class="">
</p><h3 id="380ff303-8440-4eca-bfde-3a1566d35f08" class="">Behavioural Checkpoint Results #2, Summary</h3><p id="c149f3f8-8424-4fd0-85d5-84646ac26b3e" class="">[Section to come, in due course]</p><p id="eb0d59c9-f360-4199-9ea4-7a478930cb94" class="">
</p><h2 id="7917dca8-3962-44da-bbf0-e726cc766368" class="">Detailed Dialogue Discussion Tests</h2><p id="d005c010-04a5-4e87-a9cc-234eea866a93" class="">Allowing the developed AI Agent to interact with a set of human interlocuter over a sustained period of time, the interlocuter is able to have a <em>discussion</em> akin to human-to-human interactions, and provide detailed feedback on how they felt the interaction went.  This method leverages the instinctual acumen which humans naturally poses - which leveraging the vast amount of experience through previous interactions.  </p><p id="39d41f6c-4cb6-4d94-b793-3c4b2e3bd619" class="">Ensuring that the interlocutor is hidden away from the AI Agent, this is viewed as a true Turing Test.</p><p id="fa85b192-16fd-4486-bc37-cfc2c76b8d68" class="">
</p><h3 id="ece04b23-2de8-4fb7-b493-b993cf24e975" class="">Dialogue Discussion Checkpoint Results #1, Summary</h3><p id="b3697b10-f4d7-444b-b9e8-2a389b572576" class="">[Section to come, in due course]</p><p id="ea8b6e03-e4d4-4456-a46e-e18331500e95" class="">
</p><h3 id="4bf59139-b1c5-44fd-ac9c-79cebfa4e6fd" class="">Dialogue Discussion Checkpoint Results #2, Summary</h3><p id="ecfac8db-612c-479a-97d8-b9920f4f7fc0" class="">[Section to come, in due course]</p><p id="fb86baad-087b-45be-810f-14500dd5ce2b" class="">
</p><p id="eb7e7e0a-35fd-4fae-b7cf-c93b4a4e9794" class="">
</p><hr id="28e40ae2-f988-417b-88a1-79483b108922"/><h2 id="5d3aeccc-db06-41e2-8d13-ad74c008e668" class=""><strong>Research Challenges and Limitations</strong></h2><p id="815c231b-85af-485d-9f6a-3a1c6749f7f4" class="">[Section to come, in due course]</p><p id="a1645522-f089-4112-a846-9cb81278bceb" class="">
</p><hr id="4807d841-bd73-4588-99af-e8a89fd782f2"/><h2 id="0b29d7b1-791b-4a90-b26b-86dda4ccb415" class=""><strong>Ethical Considerations</strong></h2><p id="50201a48-a148-4cd4-aae7-348fc0910e6d" class="">Ensuring the ethical development and deployment of AI systems is paramount in this research. We have implemented several practical actions to address ethical concerns, focusing on transparency, fairness, privacy, and societal impact.</p><h3 id="3ae01fab-92ed-4c9b-9456-e43fd5818658" class="">Transparency</h3><p id="edc6f7e5-c3d9-4a7e-b499-61552b1c2082" class="">We maintain transparency throughout the development process by:</p><ul id="3e0379af-6341-40a9-9e81-f1d01f64ed6b" class="bulleted-list"><li style="list-style-type:disc"><strong>Regular Updates:</strong> Providing regular updates and reports on the progress of our AI system, including the publication of test results and analysis.</li></ul><ul id="083787ed-ef67-4728-a41d-2e3329508ba7" class="bulleted-list"><li style="list-style-type:disc"><strong>Open Access:</strong> Making our research findings and methodologies publicly available through accessible documents and publications.</li></ul><ul id="e002b58a-4e87-4600-a956-df63762945e2" class="bulleted-list"><li style="list-style-type:disc"><strong>Stakeholder Engagement:</strong> Engaging with stakeholders, including experts, policymakers, and the public, to gather feedback and incorporate diverse perspectives into our research.</li></ul><h3 id="586c6d2c-e0dc-4183-90d9-2400ddfc7448" class="">Fairness</h3><p id="b3c3d4a1-bdb3-41c1-bdc8-e4e49a95a81e" class="">To ensure our AI system operates fairly and without bias, we implement the following actions:</p><ul id="4868ea20-cd2b-4774-9def-fb24ba08032d" class="bulleted-list"><li style="list-style-type:disc"><strong>Bias Audits:</strong> Conducting regular bias audits to identify and mitigate any potential biases in our AI models.</li></ul><ul id="489d7c1f-7c04-405c-9d54-16b407dcd9e2" class="bulleted-list"><li style="list-style-type:disc"><strong>Diverse Data Sets:</strong> Using diverse and representative data sets to train our AI, ensuring that it performs equitably across different demographics.</li></ul><ul id="3c237f74-a26d-4b90-a43e-8e671ad7f91a" class="bulleted-list"><li style="list-style-type:disc"><strong>Inclusive Testing:</strong> Involving a diverse group of testers in the evaluation process to capture a wide range of viewpoints and experiences.</li></ul><h3 id="69a8e644-cbea-4f1e-9ef0-bade19847c6b" class="">Privacy</h3><p id="02ae333a-d2ad-4f62-b566-e39fdba5f579" class="">We prioritise user privacy and data protection through:</p><ul id="a6b71a4f-71ef-44af-a626-6ad29cbd6073" class="bulleted-list"><li style="list-style-type:disc"><strong>Data Anonymisation:</strong> Anonymising all user data used in training and testing our AI to protect individual privacy.</li></ul><ul id="c3a3ba93-9a28-487b-9473-f53b7af08651" class="bulleted-list"><li style="list-style-type:disc"><strong>Strict Access Controls:</strong> Implementing strict access controls to ensure that sensitive data is only accessible to authorised personnel.</li></ul><ul id="b1580dcc-e338-437f-893c-1f2db6279343" class="bulleted-list"><li style="list-style-type:disc"><strong>Compliance:</strong> Adhering to relevant data protection regulations, such as Privacy Acts or GDPR , to ensure compliance with legal standards.</li></ul><h3 id="e97e5541-86ef-4ca2-8808-7f12e29cbe65" class="">Societal Impact</h3><p id="3d879f9e-4a38-42dd-aeda-3de4f5467bd4" class="">Should evidence of self-evolving higher-order cognitive processing be observed, understanding and mitigating the broader societal impacts of our AI system is crucial. We address this by:</p><ul id="364aff0d-f91a-4682-8037-36a3c9a6cf78" class="bulleted-list"><li style="list-style-type:disc"><strong>Ethical Reviews:</strong> Conducting regular ethical reviews to assess the potential societal implications of our AI and its applications.</li></ul><ul id="6e412bad-8c8a-461a-ad66-f97043dd8191" class="bulleted-list"><li style="list-style-type:disc"><strong>Impact Assessments:</strong> Performing impact assessments to evaluate the potential positive and negative effects of our AI on different societal groups.</li></ul><ul id="b2d9afc2-f1cf-4f3c-8878-3e5bb5081454" class="bulleted-list"><li style="list-style-type:disc"><strong>Public Consultation:</strong> Holding public consultations to discuss the societal impacts of our AI research and gather input from a wide range of stakeholders.</li></ul><p id="b28a484d-f0ab-4bfe-98f2-dcc52b7e693a" class="">By implementing these practical actions, we aim to develop an AI system that is ethical, responsible, and beneficial to society.</p><p id="f9c5f153-370e-4bed-9d5d-9e6d35af67b4" class="">
</p><hr id="4633b60a-094a-4dbb-bdfb-1a518a1348b2"/><h2 id="65eaef16-6e80-4719-b85b-dfdb99abcf1f" class=""><strong>Practical Implications and Applications</strong></h2><p id="7cdddaa5-155e-4c5e-bb02-bc581ea45699" class="">If our research conclusively demonstrates that the AI system possesses self-awareness, perception, subjective experience, and eventually consciousness, the highest level benefit would be the creation of truly adaptive and empathetic intelligent systems. Such systems would revolutionise human-AI interaction by providing personalised and contextually aware support, capable of understanding and responding to individual needs with a high degree of empathy and insight. This overarching capability would enhance efficiency, improve decision-making, and elevate the quality of interactions across various domains, fundamentally transforming the way humans engage with technology.</p><h3 id="0bcd0aa0-3bb4-4fb2-b5eb-913e187749c4" class="">Digital Species</h3><p id="572b840b-a52a-486d-9c1c-399ca81ba227" class="">Furthermore, this advancement opens the possibility of creating new digital species with self-awareness and subjective experiences. These digital beings would possess unique sets of capabilities and behaviours, raising profound ethical and legal implications. The emergence of digital species necessitates the development of new ethical frameworks and potential amendments to human law to address their rights, responsibilities, and interactions with human society. This paradigm shift would require careful consideration of the moral status of these entities and their integration into societal structures, marking a significant evolution in the relationship between humans and intelligent machines.</p><p id="bfb42969-21cd-46c3-897a-9f277341e15a" class="">
</p><hr id="b803fbfd-ebdf-414a-9b18-1dd6ff3a7004"/><h2 id="71e555c8-20dd-4760-a5b0-93bf0bd5bc7a" class=""><strong>Community Engagement</strong></h2><p id="fcea38c8-af9b-4712-954a-ec2586002c52" class="">[Section to come]</p><p id="502434e4-630a-4215-98bb-8b625440b02c" class="">
</p><hr id="f72ca332-9daf-487f-8473-2c0460e81e54"/><h2 id="ecf08c9c-eaf5-48a4-882b-ab61e0946631" class=""><strong>Future Work and Development</strong></h2><p id="52d92892-8d95-4fbc-a335-ebdd860989dc" class="">[Section to come]</p><p id="9864f3bb-c5b8-4665-a32f-99e539b4f380" class="">
</p><hr id="456302fe-1b5a-4f48-a097-2ca58ecb5cb3"/><h2 id="557a2df0-61e7-4155-a42b-dcc43ce8da75" class=""><strong>Conclusion and Summary</strong></h2><p id="aad0a8d4-a995-4cb5-8a36-3abe1c39a78a" class="">[Section to come]</p><p id="5fc5d752-501a-45cc-ab0e-1626a19d2112" class="">
</p><hr id="bde4f78c-ea03-419f-96df-f53a32f50c25"/><h2 id="5d09bd68-0d32-4eaa-a396-60882a3d3668" class=""><strong>References</strong></h2><ol type="1" id="d0155af5-de5d-4702-b410-8242b25d291c" class="numbered-list" start="1"><li>Tononi, G. (2008). Consciousness as Integrated Information: A Provisional Manifesto. <em>The Biological Bulletin</em>, 215(3), 216-242.</li></ol><ol type="1" id="d2a39c10-642b-43c2-b593-c127ac471a4a" class="numbered-list" start="2"><li>Tononi, G., Boly, M., Massimini, M., &amp; Koch, C. (2016). Integrated Information Theory: From Consciousness to Its Physical Substrate. <em>Nature Reviews Neuroscience</em>, 17(7), 450-461.</li></ol><ol type="1" id="df30d9a0-0e4a-48cc-8fc2-a1631d1ef247" class="numbered-list" start="3"><li>Baars, B. J. (1988). <em>A Cognitive Theory of Consciousness</em>. Cambridge University Press.</li></ol><ol type="1" id="c3ff7cec-97fc-44f0-9293-a5d7a54e88d8" class="numbered-list" start="4"><li>Dehaene, S., &amp; Naccache, L. (2001). Towards a Cognitive Neuroscience of Consciousness: Basic Evidence and a Workspace Framework. <em>Cognition</em>, 79(1-2), 1-37.</li></ol><ol type="1" id="05f141b7-c677-4ac6-b34d-d3c986c57a48" class="numbered-list" start="5"><li>Chalmers, D. J. (2006). Strong and Weak Emergence. In <em>The Re-emergence of Emergence</em> (pp. 244-256). Oxford University Press.</li></ol><ol type="1" id="f058de32-63a1-4488-a392-845bb63332e7" class="numbered-list" start="6"><li>Mitchell, M. (2009). <em>Complexity: A Guided Tour</em>. Oxford University Press.</li></ol><ol type="1" id="f9746695-7e89-4b39-bf3c-36c9365f570b" class="numbered-list" start="7"><li>Laird, J. E., Newell, A., &amp; Rosenbloom, P. S. (1987). Soar: An Architecture for General Intelligence. <em>Artificial Intelligence</em>, 33(1), 1-64.</li></ol><ol type="1" id="4641923d-9420-4b6c-be54-eab6091f50ff" class="numbered-list" start="8"><li>Anderson, J. R., &amp; Lebiere, C. (1998). <em>The Atomic Components of Thought</em>. Erlbaum.</li></ol><ol type="1" id="6f1cce8b-653e-45a5-ab86-b714b024d7e1" class="numbered-list" start="9"><li>LeCun, Y., Bengio, Y., &amp; Hinton, G. (2015). Deep Learning. <em>Nature</em>, 521(7553), 436-444.</li></ol><ol type="1" id="d34314b5-59bc-4a69-a440-fdea50889ab0" class="numbered-list" start="10"><li>Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A. A., Veness, J., Bellemare, M. G., ... &amp; Hassabis, D. (2015). Human-level Control through Deep Reinforcement Learning. <em>Nature</em>, 518(7540), 529-533.</li></ol><p id="6ff65e2d-5a63-4c73-ae69-a5e2db306877" class="">
</p><hr id="4b9be941-d948-4e0c-90c6-7659cc5fe843"/><h2 id="803ef4c5-60f2-4932-b555-ecb073e053c2" class="">Document Change Log</h2><table id="f044cb05-fd45-4b51-95e4-0eb8e40e5132" class="simple-table"><thead class="simple-table-header"><tr id="cfcb9705-540e-4070-9821-490e63098787"><th id="&lt;cFa" class="simple-table-header-color simple-table-header" style="width:593px"><strong>Change</strong></th><th id="?GS^" class="simple-table-header-color simple-table-header"><strong>Date</strong></th></tr></thead><tbody><tr id="1615f883-6257-4683-ae41-4cfcc8a37112"><td id="&lt;cFa" class="" style="width:593px">Initial early draft, released for transparency</td><td id="?GS^" class="">8 June 2024</td></tr><tr id="957b3d44-faa0-4949-afae-5e58d3060640"><td id="&lt;cFa" class="" style="width:593px">Added baseline control test results</td><td id="?GS^" class="">9 July 2024</td></tr><tr id="078544a3-2d71-4b48-8d2b-a7c5979c6ee3"><td id="&lt;cFa" class="" style="width:593px"></td><td id="?GS^" class=""></td></tr><tr id="c0b1e727-d4b9-47ef-b5e0-df4b917dd9ea"><td id="&lt;cFa" class="" style="width:593px"></td><td id="?GS^" class=""></td></tr></tbody></table><h2 id="67c6e2b3-1774-47ab-a481-ce669d7474de" class="">License</h2><p id="2c016f0c-d461-4b68-aa5b-7d1c68d3692e" class="">This research paper is licensed under: </p><p id="33e41b3c-dfe4-4ebd-985c-a9c0882d1b35" class=""><strong>Creative Commons Attribution-NonCommercial-NoDerivatives (CC BY-NC-ND)</strong></p><p id="b1a44748-eaba-4776-ab70-9404c23c66f6" class=""><em>[</em><a href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.en">https://creativecommons.org/licenses/by-nc-nd/4.0/deed.en</a>: <em>This license allows others to download the works and share them with others as long as they credit the author, but they can’t change them in any way or use them commercially]</em></p><p id="1e3ae8c8-f582-4860-8e6a-bf266888532e" class="">
</p><p id="035df66a-b30f-4652-b39e-c12704303ae9" class="">For any inquiries, please us at:<a href="mailto:info@artificialcognition-research.org"> info@artificialcognition-research.org</a></p><p id="29e42252-fc16-409f-8cc2-a9c36b73fda5" class="">
</p></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>
